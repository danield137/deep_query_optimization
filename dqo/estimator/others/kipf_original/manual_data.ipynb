{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from mscn.util import *\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: 'U' mode is deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded queries\n"
     ]
    }
   ],
   "source": [
    "joins = []\n",
    "predicates = []\n",
    "tables = []\n",
    "samples = []\n",
    "label = []\n",
    "\n",
    "with open(\"./data/train.csv\", 'rU') as f:\n",
    "    data_raw = list(list(rec) for rec in csv.reader(f, delimiter='#'))\n",
    "    for row in data_raw:\n",
    "        tables.append(row[0].split(','))\n",
    "        joins.append(row[1].split(','))\n",
    "        predicates.append(row[2].split(','))\n",
    "        if int(row[3]) < 1:\n",
    "            print(\"Queries must have non-zero cardinalities\")\n",
    "            exit(1)\n",
    "        label.append(row[3])\n",
    "predicates = [list(chunks(d, 3)) for d in predicates]\n",
    "print(\"Loaded queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['title t', 'movie_info_idx mi_idx'],\n",
       " ['t.id=mi_idx.movie_id'],\n",
       " [['t.kind_id', '=', '7'], ['mi_idx.info_type_id', '>', '99']])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0], joins[0], predicates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bitmaps\n"
     ]
    }
   ],
   "source": [
    "# Load bitmaps\n",
    "num_bytes_per_bitmap = int((1000 + 7) >> 3)\n",
    "with open(\"./data/train.bitmaps\", 'rb') as f:\n",
    "    for i in range(len(tables)):\n",
    "        four_bytes = f.read(4)\n",
    "        if not four_bytes:\n",
    "            print(\"Error while reading 'four_bytes'\")\n",
    "            exit(1)\n",
    "        num_bitmaps_curr_query = int.from_bytes(four_bytes, byteorder='little')\n",
    "        bitmaps = np.empty((num_bitmaps_curr_query, num_bytes_per_bitmap * 8), dtype=np.uint8)\n",
    "        for j in range(num_bitmaps_curr_query):\n",
    "            # Read bitmap\n",
    "            bitmap_bytes = f.read(num_bytes_per_bitmap)\n",
    "            if not bitmap_bytes:\n",
    "                print(\"Error while reading 'bitmap_bytes'\")\n",
    "                exit(1)\n",
    "            bitmaps[j] = np.unpackbits(np.frombuffer(bitmap_bytes, dtype=np.uint8))\n",
    "        samples.append(bitmaps)\n",
    "print(\"Loaded bitmaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column name dict\n",
    "column_names = get_all_column_names(predicates)\n",
    "column2vec, idx2column = get_set_encoding(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get table name dict\n",
    "table_names = get_all_table_names(tables)\n",
    "table2vec, idx2table = get_set_encoding(table_names)\n",
    "len(table2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<': array([1., 0., 0.], dtype=float32),\n",
       " '=': array([0., 1., 0.], dtype=float32),\n",
       " '>': array([0., 0., 1.], dtype=float32)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get operator name dict\n",
    "operators = get_all_operators(predicates)\n",
    "op2vec, idx2op = get_set_encoding(operators)\n",
    "op2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': array([1., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 't.id=ci.movie_id': array([0., 1., 0., 0., 0., 0.], dtype=float32),\n",
       " 't.id=mc.movie_id': array([0., 0., 1., 0., 0., 0.], dtype=float32),\n",
       " 't.id=mi.movie_id': array([0., 0., 0., 1., 0., 0.], dtype=float32),\n",
       " 't.id=mi_idx.movie_id': array([0., 0., 0., 0., 1., 0.], dtype=float32),\n",
       " 't.id=mk.movie_id': array([0., 0., 0., 0., 0., 1.], dtype=float32)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get join name dict\n",
    "join_set = get_all_joins(joins)\n",
    "join2vec, idx2join = get_set_encoding(join_set)\n",
    "join2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get min and max values for each column\n",
    "with open('./data/column_min_max_vals.csv', 'rU') as f:\n",
    "    data_raw = list(list(rec) for rec in csv.reader(f, delimiter=','))\n",
    "    column_min_max_vals = {}\n",
    "    for i, row in enumerate(data_raw):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        column_min_max_vals[row[0]] = [float(row[1]), float(row[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min log(label): 0.0\n",
      "max log(label): 19.94772801931604\n"
     ]
    }
   ],
   "source": [
    "# Get feature encoding and proper normalization\n",
    "samples_enc = encode_samples(tables, samples, table2vec)\n",
    "predicates_enc, joins_enc = encode_data(predicates, joins, column_min_max_vals, column2vec, op2vec, join2vec)\n",
    "label_norm, min_val, max_val = normalize_labels(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['title t', 'movie_companies mc', 'movie_info mi'],\n",
       " [array([0., 0., 0., ..., 0., 1., 1.], dtype=float32),\n",
       "  array([0., 1., 0., ..., 0., 0., 1.], dtype=float32),\n",
       "  array([0., 0., 1., ..., 0., 0., 0.], dtype=float32)],\n",
       " '',\n",
       " ['t.id=mc.movie_id', 't.id=mi.movie_id'],\n",
       " [array([0., 0., 1., 0., 0., 0.], dtype=float32),\n",
       "  array([0., 0., 0., 1., 0., 0.], dtype=float32)],\n",
       " '',\n",
       " [['t.production_year', '>', '1977'],\n",
       "  ['mc.company_id', '>', '71403'],\n",
       "  ['mi.info_type_id', '<', '4']],\n",
       " [array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "         0.       , 0.       , 1.       , 0.       , 0.       , 1.       ,\n",
       "         0.6978417], dtype=float32),\n",
       "  array([0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.30384347], dtype=float32),\n",
       "  array([0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.02752294], dtype=float32)])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_at=5\n",
    "tables[entry_at],samples_enc[entry_at],'', joins[entry_at],joins_enc[entry_at],'' , predicates[entry_at], predicates_enc[entry_at]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 900\n",
      "Number of validation samples: 100\n"
     ]
    }
   ],
   "source": [
    "# Split in training and validation samples\n",
    "num_queries = 1000\n",
    "num_train = int(num_queries * 0.9)\n",
    "num_test = num_queries - num_train\n",
    "\n",
    "samples_train = samples_enc[:num_train]\n",
    "predicates_train = predicates_enc[:num_train]\n",
    "joins_train = joins_enc[:num_train]\n",
    "labels_train = label_norm[:num_train]\n",
    "\n",
    "samples_test = samples_enc[num_train:num_train + num_test]\n",
    "predicates_test = predicates_enc[num_train:num_train + num_test]\n",
    "joins_test = joins_enc[num_train:num_train + num_test]\n",
    "labels_test = label_norm[num_train:num_train + num_test]\n",
    "\n",
    "print(\"Number of training samples: {}\".format(len(labels_train)))\n",
    "print(\"Number of validation samples: {}\".format(len(labels_test)))\n",
    "\n",
    "max_num_joins = max(max([len(j) for j in joins_train]), max([len(j) for j in joins_test]))\n",
    "max_num_predicates = max(max([len(p) for p in predicates_train]), max([len(p) for p in predicates_test]))\n",
    "\n",
    "dicts = [table2vec, column2vec, op2vec, join2vec]\n",
    "train_data = [samples_train, predicates_train, joins_train]\n",
    "test_data = [samples_test, predicates_test, joins_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train[0], predicates_train[0], joins_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to this point, basic encoding\n",
    "# below part is casting to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_masks = []\n",
    "sample_tensors = []\n",
    "for sample in samples_train:\n",
    "    sample_tensor = np.vstack(sample)\n",
    "    num_pad = max_num_joins + 1 - sample_tensor.shape[0]\n",
    "    sample_mask = np.ones_like(sample_tensor).mean(1, keepdims=True)\n",
    "    sample_tensor = np.pad(sample_tensor, ((0, num_pad), (0, 0)), 'constant')\n",
    "    sample_mask = np.pad(sample_mask, ((0, num_pad), (0, 0)), 'constant')\n",
    "    sample_tensors.append(np.expand_dims(sample_tensor, 0))\n",
    "    sample_masks.append(np.expand_dims(sample_mask, 0))\n",
    "sample_tensors = np.vstack(sample_tensors)\n",
    "sample_tensors = torch.FloatTensor(sample_tensors)\n",
    "sample_masks = np.vstack(sample_masks)\n",
    "sample_masks = torch.FloatTensor(sample_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 1., 1., 1.], dtype=float32),\n",
       " array([0., 1., 0., ..., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = samples_train[3]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pad = 3 + 1 - example_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor = np.vstack(example)\n",
    "example_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_mask = np.ones_like(example_tensor).mean(1, keepdims=True)\n",
    "example_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor = np.pad(example_tensor, ((0, num_pad), (0, 0)), 'constant')\n",
    "example_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones_like(example_tensor).mean(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tensors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tensors.append(np.expand_dims(example_tensor, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0., 0., 0., ..., 0., 1., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32),\n",
       " array([[[0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(example_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(example_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_masks = []\n",
    "predicate_tensors = []\n",
    "for predicate in predicates_train:\n",
    "    predicate_tensor = np.vstack(predicate)\n",
    "    num_pad = max_num_predicates - predicate_tensor.shape[0]\n",
    "    predicate_mask = np.ones_like(predicate_tensor).mean(1, keepdims=True)\n",
    "    predicate_tensor = np.pad(predicate_tensor, ((0, num_pad), (0, 0)), 'constant')\n",
    "    predicate_mask = np.pad(predicate_mask, ((0, num_pad), (0, 0)), 'constant')\n",
    "    predicate_tensors.append(np.expand_dims(predicate_tensor, 0))\n",
    "    predicate_masks.append(np.expand_dims(predicate_mask, 0))\n",
    "predicate_tensors = np.vstack(predicate_tensors)\n",
    "predicate_tensors = torch.FloatTensor(predicate_tensors)\n",
    "predicate_masks = np.vstack(predicate_masks)\n",
    "predicate_masks = torch.FloatTensor(predicate_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_masks = []\n",
    "join_tensors = []\n",
    "for join in joins_train:\n",
    "    join_tensor = np.vstack(join)\n",
    "    num_pad = max_num_joins - join_tensor.shape[0]\n",
    "    join_mask = np.ones_like(join_tensor).mean(1, keepdims=True)\n",
    "    join_tensor = np.pad(join_tensor, ((0, num_pad), (0, 0)), 'constant')\n",
    "    join_mask = np.pad(join_mask, ((0, num_pad), (0, 0)), 'constant')\n",
    "    join_tensors.append(np.expand_dims(join_tensor, 0))\n",
    "    join_masks.append(np.expand_dims(join_mask, 0))\n",
    "join_tensors = np.vstack(join_tensors)\n",
    "join_tensors = torch.FloatTensor(join_tensors)\n",
    "join_masks = np.vstack(join_masks)\n",
    "join_masks = torch.FloatTensor(join_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x1234e53c8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor = torch.FloatTensor(labels_train)\n",
    "\n",
    "dataset.TensorDataset(sample_tensors, predicate_tensors, join_tensors, target_tensor, sample_masks,\n",
    "                             predicate_masks, join_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(*train_data, labels=labels_train, max_num_joins=max_num_joins,\n",
    "                                 max_num_predicates=max_num_predicates)\n",
    "print(\"Created TensorDataset for training data\")\n",
    "test_dataset = make_dataset(*test_data, labels=labels_test, max_num_joins=max_num_joins,\n",
    "                            max_num_predicates=max_num_predicates)\n",
    "print(\"Created TensorDataset for validation data\")\n",
    "dicts, column_min_max_vals, min_val, max_val, labels_train, labels_test, max_num_joins, max_num_predicates, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "          0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "          0.0000, 0.0000, 1.0000, 0.9281],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          1.0000, 0.0000, 0.0000, 0.6606],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 1.0000, 0.0398],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]),\n",
       " tensor(0.6623),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
